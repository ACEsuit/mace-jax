{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import torch\n",
    "\n",
    "from mace_jax.haiku.torch import copy_torch_to_jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase\n",
    "import numpy as np\n",
    "from mace.data.atomic_data import AtomicData\n",
    "from mace.data.utils import config_from_atoms\n",
    "from mace.tools import torch_geometric\n",
    "from mace.tools.torch_geometric.batch import Batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_jax(batch: Batch):\n",
    "    \"\"\"Convert every tensor field in a PyG Batch to JAX arrays.\"\"\"\n",
    "    jax_dict = {}\n",
    "\n",
    "    # .keys is already a list of attribute names\n",
    "    for key in batch.keys:\n",
    "        value = batch[key]\n",
    "\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            arr = value.detach().cpu().numpy()     # to numpy\n",
    "            jax_dict[key] = jnp.asarray(arr)       # to JAX\n",
    "        else:\n",
    "            jax_dict[key] = value                  # leave as-is\n",
    "\n",
    "    return jax_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0927 13:34:57.770000 1296654 /home/pbenner/Env/mace-jax/.venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:118] No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading statistics from `statistics.json`\n"
     ]
    }
   ],
   "source": [
    "def get_statistics(filename = 'statistics.json'):\n",
    "\n",
    "    from mace.tools.multihead_tools import (  # noqa: PLC0415\n",
    "        AtomicNumberTable,\n",
    "    )\n",
    "\n",
    "    print(f\"Reading statistics from `{filename}`\")\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        statistics = json.load(f)\n",
    "\n",
    "    statistics['atomic_numbers'] = AtomicNumberTable(statistics['atomic_numbers'])\n",
    "    statistics['atomic_energies'] = [ statistics['atomic_energies'][str(i)] for i in statistics['atomic_numbers'].zs ]\n",
    "\n",
    "    return statistics\n",
    "\n",
    "statistics = get_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_args():\n",
    "\n",
    "    from mace.tools import build_default_arg_parser, check_args  # noqa: PLC0415\n",
    "\n",
    "    arguments = [\n",
    "        \"--name\"              , \"MACE_large_density\",\n",
    "        \"--interaction_first\" , \"RealAgnosticDensityInteractionBlock\",\n",
    "        \"--interaction\"       , \"RealAgnosticDensityResidualInteractionBlock\",\n",
    "        \"--num_channels\"      , \"128\",\n",
    "        \"--max_L\"             , \"2\",\n",
    "        \"--max_ell\"           , \"3\",\n",
    "        \"--num_interactions\"  , \"3\",\n",
    "        \"--correlation\"       , \"3\",\n",
    "        \"--num_radial_basis\"  , \"8\",\n",
    "        \"--MLP_irreps\"        , \"16x0e\",\n",
    "        \"--distance_transform\", \"Agnesi\",\n",
    "        \"--pair_repulsion\"\n",
    "    ]\n",
    "\n",
    "    args    = build_default_arg_parser().parse_args(arguments)\n",
    "    args, _ = check_args(args)\n",
    "\n",
    "    return args\n",
    "\n",
    "model_args = get_model_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms = ase.Atoms(\n",
    "    symbols = ['H', 'H', 'Ne', 'O'],\n",
    "    positions = np.array(\n",
    "    [\n",
    "        [0.0, 0.0, 0.0],\n",
    "        [0.5, 0.0, 0.0],\n",
    "        [0.0, 0.4, 0.0],\n",
    "        [0.0, 0.3, 0.3],\n",
    "    ]),\n",
    "    cell = np.identity(3),\n",
    "    pbc = [True, True, False],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_from_atoms(atoms)\n",
    "config.pbc = [bool(x) for x in config.pbc]\n",
    "x = AtomicData.from_config(config, z_table=statistics['atomic_numbers'], cutoff=2.0)\n",
    "x = torch_geometric.batch.Batch.from_data_list([x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare Torch model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mace.tools.model_script_utils import configure_model as configure_model_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_torch(args: argparse.Namespace, statistics):\n",
    "\n",
    "    from mace.data.utils import KeySpecification  # noqa: PLC0415\n",
    "    from mace.tools.multihead_tools import (  # noqa: PLC0415\n",
    "        prepare_default_head,\n",
    "    )\n",
    "\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "\n",
    "    args.mean = statistics['mean']\n",
    "    args.std = statistics['std']\n",
    "    args.compute_energy = True\n",
    "    args.compute_dipole = False\n",
    "    args.key_specification = KeySpecification.from_defaults()\n",
    "    args.heads = prepare_default_head(args)\n",
    "\n",
    "    model = configure_model_torch(\n",
    "        args,\n",
    "        None,\n",
    "        statistics['atomic_energies'],\n",
    "        z_table = statistics['atomic_numbers'],\n",
    "        heads = args.heads,\n",
    "        model_foundation = None,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch = get_model_torch(model_args, statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare JAX model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_model_jax(\n",
    "    args,\n",
    "    atomic_energies,\n",
    "    z_table=None,\n",
    "    model_foundation=None,\n",
    "    head_configs=None,\n",
    "):\n",
    "    import ast  # noqa: PLC0415\n",
    "\n",
    "    from e3nn_jax import Irreps  # noqa: PLC0415\n",
    "\n",
    "    from mace_jax import modules  # noqa: PLC0415\n",
    "\n",
    "    model_config = dict(\n",
    "        r_max=args.r_max,\n",
    "        num_bessel=args.num_radial_basis,\n",
    "        num_polynomial_cutoff=args.num_cutoff_basis,\n",
    "        max_ell=args.max_ell,\n",
    "        interaction_cls=modules.interaction_classes[args.interaction],\n",
    "        num_interactions=args.num_interactions,\n",
    "        num_elements=len(z_table),\n",
    "        hidden_irreps=Irreps(args.hidden_irreps),\n",
    "        edge_irreps=Irreps(args.edge_irreps) if args.edge_irreps else None,\n",
    "        atomic_energies=atomic_energies,\n",
    "        apply_cutoff=args.apply_cutoff,\n",
    "        avg_num_neighbors=args.avg_num_neighbors,\n",
    "        atomic_numbers=z_table.zs,\n",
    "        use_reduced_cg=args.use_reduced_cg,\n",
    "        use_so3=args.use_so3,\n",
    "        cueq_config=None,\n",
    "    )\n",
    "    if args.model == \"MACE\":\n",
    "        if args.interaction_first not in [\n",
    "            \"RealAgnosticInteractionBlock\",\n",
    "            \"RealAgnosticDensityInteractionBlock\",\n",
    "        ]:\n",
    "            args.interaction_first = \"RealAgnosticInteractionBlock\"\n",
    "        return modules.ScaleShiftMACE(\n",
    "            **model_config,\n",
    "            pair_repulsion=args.pair_repulsion,\n",
    "            distance_transform=args.distance_transform,\n",
    "            correlation=args.correlation,\n",
    "            gate=modules.gate_dict[args.gate],\n",
    "            interaction_cls_first=modules.interaction_classes[args.interaction_first],\n",
    "            MLP_irreps=Irreps(args.MLP_irreps),\n",
    "            atomic_inter_scale=args.std,\n",
    "            atomic_inter_shift=[0.0] * len(args.heads),\n",
    "            radial_MLP=ast.literal_eval(args.radial_MLP),\n",
    "            radial_type=args.radial_type,\n",
    "            heads=args.heads,\n",
    "            embedding_specs=args.embedding_specs,\n",
    "            use_embedding_readout=args.use_embedding_readout,\n",
    "            use_last_readout_only=args.use_last_readout_only,\n",
    "            use_agnostic_product=args.use_agnostic_product,\n",
    "        )\n",
    "    if args.model == \"ScaleShiftMACE\":\n",
    "        return modules.ScaleShiftMACE(\n",
    "            **model_config,\n",
    "            pair_repulsion=args.pair_repulsion,\n",
    "            distance_transform=args.distance_transform,\n",
    "            correlation=args.correlation,\n",
    "            gate=modules.gate_dict[args.gate],\n",
    "            interaction_cls_first=modules.interaction_classes[args.interaction_first],\n",
    "            MLP_irreps=Irreps(args.MLP_irreps),\n",
    "            atomic_inter_scale=args.std,\n",
    "            atomic_inter_shift=args.mean,\n",
    "            radial_MLP=ast.literal_eval(args.radial_MLP),\n",
    "            radial_type=args.radial_type,\n",
    "            heads=args.heads,\n",
    "            embedding_specs=args.embedding_specs,\n",
    "            use_embedding_readout=args.use_embedding_readout,\n",
    "            use_last_readout_only=args.use_last_readout_only,\n",
    "            use_agnostic_product=args.use_agnostic_product,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_jax(args: argparse.Namespace, statistics):\n",
    "\n",
    "    from mace.data.utils import KeySpecification  # noqa: PLC0415\n",
    "    from mace.tools.multihead_tools import (  # noqa: PLC0415\n",
    "        prepare_default_head,\n",
    "    )\n",
    "\n",
    "    args.mean = statistics['mean']\n",
    "    args.std = statistics['std']\n",
    "    args.compute_energy = True\n",
    "    args.compute_dipole = False\n",
    "    args.key_specification = KeySpecification.from_defaults()\n",
    "    args.heads = prepare_default_head(args)\n",
    "\n",
    "    model = configure_model_jax(\n",
    "        args,\n",
    "        statistics['atomic_energies'],\n",
    "        z_table = statistics['atomic_numbers'],\n",
    "        model_foundation = None,\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(x):\n",
    "    model_jax = get_model_jax(model_args, statistics)\n",
    "    return model_jax(batch_to_jax(x))\n",
    "\n",
    "transformed = hk.transform_with_state(forward_fn)\n",
    "rng = jax.random.PRNGKey(42)\n",
    "params, state = transformed.init(rng, x)\n",
    "params = copy_torch_to_jax(model_torch, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbenner/Env/mace-jax/mace-jax/mace_jax/modules/models.py:70: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in array is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  self.atomic_numbers = jnp.array(atomic_numbers, dtype=jnp.int64)\n",
      "/home/pbenner/Env/mace-jax/mace-jax/mace_jax/e3nn/math/_normalize_activation.py:12: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'>  is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  z = jax.random.normal(key, shape=(1_000_000,), dtype=jnp.float64).astype(dtype)\n",
      "/home/pbenner/Env/mace-jax/mace-jax/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:124: UserWarning: Explicitly requested dtype <class 'jax.numpy.float64'> requested in astype is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n",
      "/home/pbenner/Env/mace-jax/mace-jax/.venv/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:124: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/jax-ml/jax#current-gotchas for more.\n",
      "  return lax_numpy.astype(self, dtype, copy=copy, device=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'energy': Array([280.80872], dtype=float32),\n",
       " 'node_energy': Array([ 16.895023 ,   0.3773191, 140.834    , 122.70241  ], dtype=float32),\n",
       " 'interaction_energy': Array([287.8191], dtype=float32),\n",
       " 'displacement': Array([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]], dtype=float32),\n",
       " 'node_feats': Array([[-0.00262905, -0.0130656 , -0.00300795, ..., -0.00437343,\n",
       "          0.00266318, -0.00324484],\n",
       "        [-0.00262307, -0.01277524, -0.00259772, ..., -0.00418743,\n",
       "          0.00260948, -0.00309471],\n",
       "        [-0.01275518, -0.00670953, -0.01058813, ...,  0.00162463,\n",
       "          0.00178794, -0.00545055],\n",
       "        [-0.00034387,  0.00324182, -0.02052504, ...,  0.00081145,\n",
       "         -0.00162839, -0.00519255]], dtype=float32)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, state = transformed.apply(params, state, rng, x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mace-jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
